---
title: "Spotify Wrapped"
author: "Julie Deckers"
date: "2/13/2021"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
   

---

```{r setup, echo=FALSE, include=FALSE}
knitr::opts_chunk$set(message=FALSE, echo = FALSE)
```

```{r}
library(tidyverse)
library(compmus)
library(ggplot2)
library(spotifyr)
library(plotly)
library(Cairo)
library(dplyr)

Julie <- get_playlist_audio_features("","37i9dQZF1EM27HE4pdYYcz") 
Hemke <- get_playlist_audio_features("","37i9dQZF1EMgeVFiZwhb4Z")
Fleur <- get_playlist_audio_features("","37i9dQZF1EMd6LXIgrTylx")

Spotify_Wrapped <-
  bind_rows(
    Julie %>% mutate(category = "Julie"),
    Hemke %>% mutate(category = "Hemke"),
    Fleur %>% mutate(category = "Fleur")
      )
```


### Major or Minor? 
```{r}
Spotify_Wrapped$mode_factor <- factor(Spotify_Wrapped$mode, levels = c(1,0), labels = c("Major", "Minor"))

```


```{r}

plotmode<-ggplot(Spotify_Wrapped, aes(x = mode_factor, fill = category)) +
geom_bar(position = position_dodge()) +
labs(x = "Mode", y = "Count")
                                                                                
ggplotly(plotmode)
```

***
Here you can see the mode of the songs in our playlists. We all have more major songs, which I expected. But we still have quite a lot of minor songs, which I didn't expect. 

### A variety of keys 

```{r}

plotkeys<-ggplot(Spotify_Wrapped, aes(x = key,fill=category,label=track.name)) +
  geom_histogram()
ggplotly(plotkeys)
```

***
This is an overview of the keys of the songs in our playlists. We all have the most songs in C. I found it interesting to see that I have 6 songs in D#/Eb and Fleur and Hemke only 2 each. All three of us have the same amount of songs in A, namely 9 each. 

### Different tempi's

```{r}
plottempi<-ggplot(Spotify_Wrapped,aes(x = tempo, fill=category, label=track.name)) +
  geom_histogram()
ggplotly(plottempi)
```

***
This shows the different tempi of the songs in our playlists. The most songs are around 120BPM. We all have a few very fast songs, but the rest is pretty average. The peak is at 120BPM. 120BPM is what most people prefer. The songs with a fast tempo in my playlist are "Small Talk", "Fired Up", "Vossi Bop" en "Lost In Yesterday". Hemke's two songs are "Small Talk" and "Vossi Bop", the same as two of mine. Fleur's one is "GUESS WHAT? (feat. XakiMichele)"


### "December", Fleur's most listened song  

#### Onsets of "December"
```{r}
decemberF <-
  get_tidy_audio_analysis("2XTyx7Txuj6dZ1lLYLj3Wc") %>%
  select(segments) %>%
  unnest(segments)

decemberF %>%
  mutate(loudness_max_time = start + loudness_max_time) %>%
  arrange(loudness_max_time) %>%
  mutate(delta_loudness = loudness_max - lag(loudness_max)) %>%
  ggplot(aes(x = loudness_max_time, y = pmax(0, delta_loudness))) +
  geom_line() +
  xlim(0, 30) +
  theme_minimal() +
  labs(x = "Time (s)", y = "Novelty")

```

****
In this plot you can see the onsets,which is where things change in the song. It has a lot of high peaks. 
#### Tempogram Of "December"
```{r}
decemberF <-
  get_tidy_audio_analysis("2XTyx7Txuj6dZ1lLYLj3Wc")

decemberF%>%
tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```



****
Here you can see that "December" has a clear beat, which you can see the tempogram you can see a nice yellow line of the beat.

### Tempogram of "WHAT'S GOOD", one of Julie's songs

#### Novelty and onsets

```{r}
whatsgood <- get_tidy_audio_analysis("6bOkaEXc5CopinGazSLokx")

whatsgood <- get_tidy_audio_analysis("6bOkaEXc5CopinGazSLokx")%>%
   select(segments) %>%
  unnest(segments)

whatsgood %>%
  mutate(loudness_max_time = start + loudness_max_time) %>%
  arrange(loudness_max_time) %>%
  mutate(delta_loudness = loudness_max - lag(loudness_max)) %>%
  ggplot(aes(x = loudness_max_time, y = pmax(0, delta_loudness))) +
  geom_line() +
  xlim(0, 30) +
  theme_minimal() +
  labs(x = "Time (s)", y = "Novelty")


```

****
This plot shows the onsets of the "WHAT's GOOD". It begins with a very high peak, but the rest are a lot smaller.
#### Tempogram
```{r}
whatsgood <- get_tidy_audio_analysis("6bOkaEXc5CopinGazSLokx")

whatsgood %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```

****
"WHAT'S GOOD" has an evident tempo, as you can see from the yellow line in the tempogram. The parts where there is more yellow at the bottom en top too, the song has an instrument (I think a synthesizer) that creates a kind of grainy noise.



### Comparing Three Spotify Wrapped Playlists
For my corpus I would like to compare my Spotify Wrapped playlist to my friends and familys Wrapped playlitst. The reason I chose this is because I think that a lot of people like the Wrapped playlists and its a fun way to see what you listened to the previous year. I also think it's interesting to see if the playlists are accurate and if the persons actually listened to the songs in it. I think it's fun to just see what I listened to and what my friends listend to, and what the difference is. 

I have 2 Wrapped playlists to compare to mine. I know mine has a lot of pop music in it, so I expect it will have a lot of songs in it with a fast tempo and a high valence. One of my friends, Hemke, listened to a few artists that i also listened to, so i expect ours will have some similar features. My other friend, Fleur, listens to more rap music, so i expect hers to have al lot of energy and maybe danceability. Fleur has a lot of songs in her playlist that I dont know, so i think it will be interessting to see how it compares to mine and Hemke's playlists. I expect it will be quite different to ours. We all listen to music only in Spotify, so I think the information that i get from the playlists will be accurate.








### **Fleur** likes to dance 
```{r}

library(tidyverse)
library(ggplot2)
library(spotifyr)
library(plotly)
library(Cairo)
library(dplyr)

Julie <- get_playlist_audio_features("","37i9dQZF1EM27HE4pdYYcz") 
Hemke <- get_playlist_audio_features("","37i9dQZF1EMgeVFiZwhb4Z")
Fleur <- get_playlist_audio_features("","37i9dQZF1EMd6LXIgrTylx")

Spotify_Wrapped <-
  bind_rows(
    Julie %>% mutate(category = "Julie"),
    Hemke %>% mutate(category = "Hemke"),
    Fleur %>% mutate(category = "Fleur")
      )
```

```{r}
plotf<-ggplot(Fleur,aes(x=valence,y=danceability,size =energy,label=track.name,alpha=0.5)) + geom_point() +ggtitle("Fleur") + geom_smooth() + expand_limits(x = 0, y = 0)

ggplotly(plotf)


```
***
As you can see in this scatterplot Fleur's playlist has a lot danceability, so that matches with my previous statement that Fleur listens to a lot of hiphop. Her playlist also has a decent amount of energy. There is only one song with low energy, namely "i love you"by Billie Eilish. 


### **Julie**, from low to high

```{r}
plotj <-ggplot(Julie,aes(x=valence,y=danceability,size=energy, label=track.name, alpha=0.5)) + geom_point() +ggtitle("Julie") + geom_smooth() + expand_limits(x = 0, y = 0)

ggplotly(plotj)
```
*** 
My playlist is a bit of a mix. I have songs that have low energy, but also high. The same goes for valence and danceability. If you compare my danceability with fleur's, it is a lot lower than Fleur's. 


### **Hemke** is the middle ground

```{r}
ploth<-ggplot(Hemke,aes(x=valence,y=danceability,size=energy,label=track.name,alpha=0.5)) + geom_point() +ggtitle("Hemke") + geom_smooth() +expand_limits(x = 0, y = 0)

ggplotly(ploth)
```
*** 
Hemke's danceablity level is centered in the middle erea in the plot. This also counts for the valence and energy. It's very straight forward, in the best way of course, with a few outliers.


### How does it look if the playlist are in one plot?

```{r}
library(tidyverse)
library(ggplot2)
library(spotifyr)
library(plotly)
library(Cairo)
library(dplyr)

Julie <- get_playlist_audio_features("","37i9dQZF1EM27HE4pdYYcz") 
Hemke <- get_playlist_audio_features("","37i9dQZF1EMgeVFiZwhb4Z")
Fleur <- get_playlist_audio_features("","37i9dQZF1EMd6LXIgrTylx")

Spotify_Wrapped <-
  bind_rows(
    Julie %>% mutate(category = "Julie"),
    Hemke %>% mutate(category = "Hemke"),
    Fleur %>% mutate(category = "Fleur")
      )




```






```{r}
plot1 <- ggplot(Spotify_Wrapped,aes(x=valence,y=danceability,color=category,size=energy, alpha=0.5,label=track.name)) + geom_point() +ggtitle("All three playlists together") + geom_smooth() 

ggplotly(plot1)


```

***
In this plot you can better see that Fleur's playlist has more dancebaility than my and Hemke's playlist. You can also see that my and hemke's playlist lie very close together, but that mine has a bit less danceability and energy. The features were very similar to what I expected. I didn't really expect that mine would have as many songs with low energy, valence and danceability as it has. I'll go one by one through the outliers of all three of the playlists. 

I'll start with my playlist. The songs with the lowest danceability (under 0.3) are "Once Upon a December", "All is Found", "Still Hurting", Beethoven's 3th symphony, "Davy Jones" and "Exile ft. Bon Iver". All these songs, exept the last one, are musical numbers or instrumental numbers, so it makes sense that they have low danceability. "Davy Jones" and Beethoven's 3th are also the ones with the lowest energy (under 0.1). The ones with the lowest valence (under 0.1) are "Fine Line", "No Time To Die", "Falling", "My Future" and again "Once Upon a December". These songs are slow ballet songs. 

Fleur's song with low energy is "i love you" from Billie Eilish. The songs with the lowest danceability (under 0.3) are "Mumzy" and "When We Were Young". 

Hemke's songs with the lowest danceability are "Venus In Furs" and "Answer to Yourself". 

I noticed that here are a few kind of turquoise dots. Those are songs that Hemke and I have in common. They are all songs from Harry styles.

### (new) Histogram of energy
```{r}
Julie <- get_playlist_audio_features("","37i9dQZF1EM27HE4pdYYcz") 
Hemke <- get_playlist_audio_features("","37i9dQZF1EMgeVFiZwhb4Z")
Fleur <- get_playlist_audio_features("","37i9dQZF1EMd6LXIgrTylx")

Spotify_Wrapped <-
  bind_rows(
    Julie %>% mutate(category = "Julie"),
    Hemke %>% mutate(category = "Hemke"),
    Fleur %>% mutate(category = "Fleur")
      )

Spotify_Wrapped %>%
  ggplot(aes(x = energy)) +
  geom_histogram(binwidth = 0.1) +
  facet_wrap(~category)


```

***

Fleur's playlist lies between the middle and the higher levels of energy. Hemke's is mostly high. My playlist is a mix of low, middle and high. This is what i expected. 


### (new) Chromagram of "Davy Jones" from Pirates of the Caribbean, outlier from Julie's playlist.
```{r}
library(compmus)
library(tidyverse)
library(ggplot2)
library(spotifyr)
library(plotly)
library(Cairo)
library(dplyr)

davy <-
  get_tidy_audio_analysis("7klLXey9V4OrC6mwUXf8Fc") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

davy %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```
 
***

This is a chromagram of "Davy jones" from Pirates of the Caribbean. This Song is from Julie's playlist and has the lowest danceability, valence and energy of all the playlists.

### (new) Self similairity matrix of "Leaders" from Lil Uzi Vert, outlier of Fleur's playlist.


```{r}
library(compmus)
library(tidyverse)
library(ggplot2)
library(spotifyr)
library(plotly)
library(Cairo)
library(dplyr)

leaders <-
  get_tidy_audio_analysis("4D7NrSeqkTarBrJ80b2sBc") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  leaders %>%
    compmus_self_similarity(pitches, "aitchison") %>%
    mutate(d = d / max(d), type = "Chroma"),
  leaders %>%
    compmus_self_similarity(timbre, "euclidean") %>%
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")




```

***
This is a self similairity matrix of "leaders". This song is from Fleur's playlist and has the most danceability, valence and energy of all the playlists.

### Chordogram of "Venus in Furs" by The Velvet Underground, outlier of Hemke's playlist.



```{r}


circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

venusinfurs <-
  get_tidy_audio_analysis("29engDqjmMr3VLqMm0c0WE") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

venusinfurs %>% 
  compmus_match_pitch_template(
    key_templates,         
    method = "euclidean",  
    norm = "manhattan"     
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")


```

***

This is chordogram of "Venus in Furs", one of the outliers of Hemke's playlist. The darkestcolors of the chords are G#min, C#min, Abmaj and Dbmaj. Around the 100 and 200 seconds this changes. Then it is Emaj and Emin. The song ends with a fade out, so this explains the lighter colors. It has a very clear chord progressions. And you can also hear it in the song very clearly. 

### Chrordogram of "Sunflower, vol 6." by Harry Styles
```{r}

circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

sun6 <-
  get_tidy_audio_analysis("6iYMfxznTBlcVOgRHab2W0") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

sun6 %>% 
  compmus_match_pitch_template(
    key_templates,         
    method = "euclidean",  
    norm = "manhattan"     
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

*** 
This is a chordogram of "Sunflower, VOl. 6" by Harry Styles. I thought it would be interesting to look at one of Harry styles songs since Hemke and I both listened to his songs. The chords that are used in this song are Cmaj, Fmaj, Cmin and Fmin. Bbmin also gets used but not a lot. The song begins and ends with a fade in/out, which the lighter colors in the beginning and ending of the chordogram show. It's an upbeat song. I didn't expect there to be so little dark colors, so not a very distinctive key or main chord maybe. The Fmaj chord around 125 seconds is a vocal harmony with many layers of vocals. 

### Chordogram of  "i love you" by Billie Eillish, one of Fleur's outliers

```{r}

circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

iloveyou <-
  get_tidy_audio_analysis("6CcJMwBtXByIz4zQLzFkKc") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

iloveyou %>% 
  compmus_match_pitch_template(
    key_templates,         
    method = "euclidean",  
    norm = "manhattan"     
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")


```

***
This is a chordogram of "i love you" by Billie Eillish, one of the ouliers of Fleur's playlist. It's a very quiet and calm song with only the guitar and a little bit of piano as instruments.The lighter bloks show this. The main chords that are used are Cmaj,Amin Emin and Fmaj. During the darker blok from around 110 seconds to 225 seconds, the second verse starts, which has some background noises, and the chorus and bridge are played, which  have more dynamics that before. 


### Conclusion








